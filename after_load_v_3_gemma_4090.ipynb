{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c4a363",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac147d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-text-splitters\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-huggingface\n",
      "  Using cached langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
      "Collecting langchain-chroma\n",
      "  Using cached langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Using cached langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.2.3-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.12.13-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.7.0-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.3-cp310-cp310-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.1-cp310-cp310-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting huggingface-hub>=0.30.2 (from langchain-huggingface)\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting chromadb>=1.0.9 (from langchain-chroma)\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.30.2->langchain-huggingface)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading pybase64-1.4.1-cp310-cp310-win_amd64.whl.metadata (8.7 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading onnxruntime-1.22.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting overrides>=7.3.1 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading grpcio-1.73.1-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading orjson-3.10.18-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
      "Collecting httpx>=0.27.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting rich>=10.11.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma) (0.4.6)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting anyio (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (3.23.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.67-py3-none-any.whl (440 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.4/2.5 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 11.2 MB/s eta 0:00:00\n",
      "Using cached aiohttp-3.12.13-cp310-cp310-win_amd64.whl (450 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-win_amd64.whl (45 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
      "Downloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
      "Downloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
      "Downloading transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/10.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/10.8 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.1/10.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/10.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.4/2.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 10.3 MB/s eta 0:00:00\n",
      "Using cached torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.4/19.5 MB 12.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 4.7/19.5 MB 12.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 7.3/19.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 9.7/19.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 12.1/19.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 14.4/19.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 16.8/19.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.5/19.5 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.7.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached greenlet-3.2.3-cp310-cp310-win_amd64.whl (296 kB)\n",
      "Downloading grpcio-1.73.1-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.3 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 11.9 MB/s eta 0:00:00\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "Downloading orjson-3.10.18-cp310-cp310-win_amd64.whl (134 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading onnxruntime-1.22.0-cp310-cp310-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.7 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.7/12.7 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.7 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached propcache-0.3.2-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pybase64-1.4.1-cp310-cp310-win_amd64.whl (36 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rpds_py-0.26.0-cp310-cp310-win_amd64.whl (231 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Downloading watchfiles-1.1.0-cp310-cp310-win_amd64.whl (292 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=2b691567a89799503064fe44ff9f54478dd5caab40933507f227384eeb3db3c0\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, mpmath, flatbuffers, durationpy, zstandard, websockets, websocket-client, urllib3, typing-inspection, tqdm, tomli, tenacity, sympy, sniffio, shellingham, safetensors, rpds-py, regex, PyYAML, python-dotenv, pyreadline3, pyproject_hooks, pypdf, pydantic-core, pybase64, pyasn1, protobuf, propcache, packaging, overrides, orjson, oauthlib, numpy, networkx, mypy-extensions, multidict, mmh3, mdurl, MarkupSafe, jsonpointer, importlib-resources, idna, httpx-sse, httptools, h11, grpcio, greenlet, fsspec, frozenlist, filelock, distro, click, charset_normalizer, certifi, cachetools, bcrypt, backoff, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspect, SQLAlchemy, rsa, requests, referencing, pydantic, pyasn1-modules, opentelemetry-proto, opentelemetry-api, marshmallow, markdown-it-py, jsonpatch, jinja2, humanfriendly, httpcore, googleapis-common-protos, build, anyio, aiosignal, watchfiles, torch, rich, requests-toolbelt, requests-oauthlib, pydantic-settings, posthog, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, jsonschema-specifications, huggingface-hub, httpx, google-auth, dataclasses-json, coloredlogs, aiohttp, typer, tokenizers, opentelemetry-sdk, onnxruntime, langsmith, kubernetes, jsonschema, transformers, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, langchain-huggingface, chromadb, langchain-chroma, langchain, langchain-community\n",
      "\n",
      "   ----------------------------------------   1/114 [mpmath]\n",
      "   ----------------------------------------   1/114 [mpmath]\n",
      "   - --------------------------------------   5/114 [websockets]\n",
      "   -- -------------------------------------   6/114 [websocket-client]\n",
      "   --- ------------------------------------   9/114 [tqdm]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  12/114 [sympy]\n",
      "   ---- -----------------------------------  14/114 [shellingham]\n",
      "   ------ ---------------------------------  18/114 [PyYAML]\n",
      "   ------- --------------------------------  22/114 [pypdf]\n",
      "   ------- --------------------------------  22/114 [pypdf]\n",
      "   -------- -------------------------------  25/114 [pyasn1]\n",
      "   --------- ------------------------------  26/114 [protobuf]\n",
      "  Attempting uninstall: packaging\n",
      "   --------- ------------------------------  26/114 [protobuf]\n",
      "    Found existing installation: packaging 25.0\n",
      "   --------- ------------------------------  26/114 [protobuf]\n",
      "    Uninstalling packaging-25.0:\n",
      "   --------- ------------------------------  26/114 [protobuf]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   --------- ------------------------------  26/114 [protobuf]\n",
      "   ---------- -----------------------------  31/114 [oauthlib]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  32/114 [numpy]\n",
      "   ----------- ----------------------------  33/114 [networkx]\n",
      "   ----------- ----------------------------  33/114 [networkx]\n",
      "   ----------- ----------------------------  33/114 [networkx]\n",
      "   ----------- ----------------------------  33/114 [networkx]\n",
      "   ----------- ----------------------------  33/114 [networkx]\n",
      "   ----------- ----------------------------  33/114 [networkx]\n",
      "   ----------- ----------------------------  33/114 [networkx]\n",
      "   -------------- -------------------------  40/114 [importlib-resources]\n",
      "   --------------- ------------------------  43/114 [httptools]\n",
      "   --------------- ------------------------  45/114 [grpcio]\n",
      "   ---------------- -----------------------  46/114 [greenlet]\n",
      "   ---------------- -----------------------  47/114 [fsspec]\n",
      "   ----------------- ----------------------  51/114 [click]\n",
      "   -------------------- -------------------  57/114 [attrs]\n",
      "   --------------------- ------------------  62/114 [uvicorn]\n",
      "   ---------------------- -----------------  64/114 [SQLAlchemy]\n",
      "   ---------------------- -----------------  64/114 [SQLAlchemy]\n",
      "   ---------------------- -----------------  64/114 [SQLAlchemy]\n",
      "   ---------------------- -----------------  64/114 [SQLAlchemy]\n",
      "   ---------------------- -----------------  65/114 [rsa]\n",
      "   ----------------------- ----------------  67/114 [referencing]\n",
      "   ----------------------- ----------------  68/114 [pydantic]\n",
      "   ------------------------ ---------------  69/114 [pyasn1-modules]\n",
      "   ------------------------ ---------------  70/114 [opentelemetry-proto]\n",
      "   ------------------------- --------------  73/114 [markdown-it-py]\n",
      "   -------------------------- -------------  75/114 [jinja2]\n",
      "   --------------------------- ------------  77/114 [httpcore]\n",
      "   --------------------------- ------------  78/114 [googleapis-common-protos]\n",
      "   ---------------------------- -----------  80/114 [anyio]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  83/114 [torch]\n",
      "   ----------------------------- ----------  84/114 [rich]\n",
      "   ----------------------------- ----------  85/114 [requests-toolbelt]\n",
      "   ------------------------------ ---------  88/114 [posthog]\n",
      "   ------------------------ ------  89/114 [opentelemetry-semantic-conventions]\n",
      "   ------------------------ ------  89/114 [opentelemetry-semantic-conventions]\n",
      "   -------------------------------- -------  92/114 [huggingface-hub]\n",
      "   -------------------------------- -------  92/114 [huggingface-hub]\n",
      "   -------------------------------- -------  92/114 [huggingface-hub]\n",
      "   -------------------------------- -------  94/114 [google-auth]\n",
      "   -------------------------------- -------  94/114 [google-auth]\n",
      "   ---------------------------------- -----  97/114 [aiohttp]\n",
      "   ---------------------------------- -----  97/114 [aiohttp]\n",
      "   ----------------------------------- ---- 100/114 [opentelemetry-sdk]\n",
      "   ----------------------------------- ---- 101/114 [onnxruntime]\n",
      "   ----------------------------------- ---- 101/114 [onnxruntime]\n",
      "   ----------------------------------- ---- 101/114 [onnxruntime]\n",
      "   ----------------------------------- ---- 101/114 [onnxruntime]\n",
      "   ----------------------------------- ---- 101/114 [onnxruntime]\n",
      "   ----------------------------------- ---- 101/114 [onnxruntime]\n",
      "   ----------------------------------- ---- 102/114 [langsmith]\n",
      "   ----------------------------------- ---- 102/114 [langsmith]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 103/114 [kubernetes]\n",
      "   ------------------------------------ --- 104/114 [jsonschema]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------ --- 105/114 [transformers]\n",
      "   ------------------------------------- -- 107/114 [langchain-core]\n",
      "   ------------------------------------- -- 107/114 [langchain-core]\n",
      "   -------------------------------------- - 110/114 [chromadb]\n",
      "   -------------------------------------- - 110/114 [chromadb]\n",
      "   -------------------------------------- - 110/114 [chromadb]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  112/114 [langchain]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------  113/114 [langchain-community]\n",
      "   ---------------------------------------- 114/114 [langchain-community]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 async-timeout-4.0.3 attrs-25.3.0 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 certifi-2025.6.15 charset_normalizer-3.4.2 chromadb-1.0.15 click-8.2.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 distro-1.9.0 durationpy-0.10 filelock-3.18.0 flatbuffers-25.2.10 frozenlist-1.7.0 fsspec-2025.5.1 google-auth-2.40.3 googleapis-common-protos-1.70.0 greenlet-3.2.3 grpcio-1.73.1 h11-0.16.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 httpx-sse-0.4.1 huggingface-hub-0.33.2 humanfriendly-10.0 idna-3.10 importlib-resources-6.5.2 jinja2-3.1.6 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 langchain-0.3.26 langchain-chroma-0.2.4 langchain-community-0.3.27 langchain-core-0.3.67 langchain-huggingface-0.3.0 langchain-text-splitters-0.3.8 langsmith-0.4.4 markdown-it-py-3.0.0 marshmallow-3.26.1 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 multidict-6.6.3 mypy-extensions-1.1.0 networkx-3.4.2 numpy-2.2.6 oauthlib-3.3.1 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 orjson-3.10.18 overrides-7.7.0 packaging-24.2 posthog-5.4.0 propcache-0.3.2 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.1 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 pypdf-5.7.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.1.1 referencing-0.36.2 regex-2024.11.6 requests-2.32.4 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.0.0 rpds-py-0.26.0 rsa-4.9.1 safetensors-0.5.3 shellingham-1.5.4 sniffio-1.3.1 sympy-1.14.0 tenacity-9.1.2 tokenizers-0.21.2 tomli-2.2.1 torch-2.7.1 tqdm-4.67.1 transformers-4.53.0 typer-0.16.0 typing-inspect-0.9.0 typing-inspection-0.4.1 urllib3-2.5.0 uvicorn-0.35.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1 yarl-1.20.1 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain langchain-community langchain-text-splitters langchain-huggingface langchain-chroma pypdf transformers torch accerlate timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9cae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\llm_p_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoModel\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579594f",
   "metadata": {},
   "source": [
    "## GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e78c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : cuda\n",
      "  GPU : 1\n",
      " GPU : NVIDIA GeForce RTX 4090\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\" : {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"  GPU : {torch.cuda.device_count()}\")\n",
    "    print(f\" GPU : {torch.cuda.get_device_name(0)}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a0877",
   "metadata": {},
   "source": [
    "## 1.   (, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c7294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] PDF     \n",
      "PDF    .     : 1038\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"[1] PDF     \")\n",
    "\n",
    "pdf_path = r'C:\\Users\\user\\Documents\\workspace_llm\\workspace_llm_p_2\\3_ocr.pdf'\n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\": PDF    .  : {pdf_path}\")\n",
    "    exit()\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(documents)\n",
    "print(f\"PDF    .     : {len(all_splits)}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a407249",
   "metadata": {},
   "source": [
    "## 2.   ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ()  \n"
     ]
    }
   ],
   "source": [
    "model_name = \"BAAI/bge-m3\"\n",
    "\n",
    "embedding_function = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device':'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings':True} #  \n",
    ")\n",
    "print(\" ()  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235eb2c5",
   "metadata": {},
   "source": [
    "## 3.  db  (,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e75d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]  DB   Retriever  \n",
      " Chroma   .\n",
      "    .\n",
      " Retriever  . ( 7  )\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"[3]  DB   Retriever  \")\n",
    "\n",
    "\n",
    "persist_directory = './chroma_db_gemma3_n_test_v1'\n",
    "\n",
    "if not os.path.exists(persist_directory):\n",
    "    print(\" Chroma   . (   ...)\")\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=all_splits,\n",
    "        embedding=embedding_function,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    print(\"      .\")\n",
    "else:\n",
    "    print(\" Chroma   .\")\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    print(\"    .\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 7})\n",
    "print(\" Retriever  . ( 7  )\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550586d5",
   "metadata": {},
   "source": [
    "## llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23647c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] LLM  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|| 3/3 [00:03<00:00,  1.10s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLM   : {llm_model_id}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"[4] LLM  \")\n",
    "\n",
    "llm_model_id = \"google/gemma-3n-E2B-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_id)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    llm_model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\" # triton  :   pytorch  \n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=llm_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.2, \n",
    "    return_full_text=False \n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "print(\" LLM   : {llm_model_id}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d99b0f",
   "metadata": {},
   "source": [
    "##   RAG Chain \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] RAG   \n",
      " RAG   .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"[5] RAG   \")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"<start_of_turn>user\n",
    "You are a Q&A bot that must answer the user's Question using only the provided Retrieved Documents.\n",
    "\n",
    "**Your mission:**\n",
    "1. Fully comprehend and analyze the content of the Retrieved Documents.\n",
    "2. Never use your prior knowledge or any external information. You must base your answers solely on what is explicitly stated in the Retrieved Documents.\n",
    "3. If the answer to the question clearly exists within the Retrieved Documents, locate it and provide the correct answer along with a detailed explanation.\n",
    "4. If you cannot find the answer to the question within the Retrieved Documents, do not guesshonestly respond, I cannot answer based on the provided documents.\n",
    "\n",
    "\n",
    "**think step-by-step inside a <thinking> block to analyze the problem:**\n",
    "1.  Identify the core question the user is asking.\n",
    "2.  Scan the 'Context' to find the multiple-choice question and its options that match the user's query.\n",
    "3.  Locate any text in the 'Context' that serves as an explanation, a definition, or a clue to the correct answer.\n",
    "4.  Determine the correct option based on the evidence found.\n",
    "5.  Formulate a clear explanation based on your findings.\n",
    "\n",
    "After your thinking process, generate the final user-facing answer in Korean, strictly following the format below.\n",
    "\n",
    "## Final Answer Format:\n",
    "**Final Answer :**\n",
    "[   . : .     .]\n",
    "\n",
    "**:**\n",
    "[        . :        .]\n",
    "\n",
    "---\n",
    "**IMPORTANT**: If the provided 'Context' is insufficient to determine the correct answer and provide a clear explanation, your final answer must be: \"         .\" Do not use any external knowledge.\n",
    "\n",
    "# Context:\n",
    "{context}\n",
    "\n",
    "# Question:\n",
    "{input}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "<thinking>\n",
    "1. Identify the core question.\n",
    "2. Locate the matching question and options in the Context.\n",
    "3. Find evidence (definitions, explanations, clues) in the Context.\n",
    "4. Select the correct option based on evidence.\n",
    "5. Prepare a clear explanation.\n",
    "</thinking>\n",
    "\"\"\")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "print(\" RAG   .\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ed321",
   "metadata": {},
   "source": [
    "##  (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] RAG  \n",
      " :         ? .    .   10   22.5         .       (tank)   .   (tank air vent)     \n",
      "\n",
      "--- [  (Context)] ---\n",
      " 1:       ? \n",
      ".   \n",
      ".   10   \n",
      " 22.5    \n",
      "    \n",
      ".       \n",
      " (tank)  ...\n",
      " 2:    \n",
      "       \n",
      "   .\n",
      "223       \n",
      "      ?\n",
      ".      \n",
      "  \n",
      ". ...\n",
      " 3: 217        \n",
      "?\n",
      ".   15[ppm]   \n",
      "  \n",
      ".  25   \n",
      "      \n",
      " \n",
      ".       ...\n",
      " 4: s\n",
      ".        \n",
      "  .\n",
      "/         \n",
      "   .\n",
      "162        \n",
      "     \n",
      " ?\n",
      "....\n",
      " 5: .       \n",
      "      \n",
      "1.       \n",
      ".      \n",
      "    \n",
      "/     25 \n",
      "...\n",
      " 6:  47  472    \n",
      "     .\n",
      "1.        \n",
      "    \n",
      "\n",
      "2.       \n",
      " ...\n",
      " 7:  .\n",
      ".    \n",
      " .\n",
      ".      \n",
      " .\n",
      "04.       \n",
      "  ?\n",
      ".      \n",
      ".\n",
      ". ...\n",
      "------------------------------\n",
      "--- [ ] ---\n",
      "## Final Answer:\n",
      "**Final Answer:** .       (tank)  \n",
      "**:**      .\n",
      "1)  :  \n",
      "2)  :   10   22.5        \n",
      "3)  : ,,,,,,, , ,                \n",
      ",       (tank)       .\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[6] RAG  \")\n",
    "question = \"        ? .    .   10   22.5         .       (tank)   .   (tank air vent)     \"\n",
    "\n",
    "print(f\" : {question}\\n\")\n",
    "\n",
    "response = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "print(\"--- [  (Context)] ---\")\n",
    "for i, doc in enumerate(response[\"context\"]):\n",
    "    print(f\" {i+1}: {doc.page_content[:150]}...\")\n",
    "    \n",
    "print(\"-\" * 30)\n",
    "print(\"--- [ ] ---\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1352d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d4844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3d348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a039ef30",
   "metadata": {},
   "source": [
    "1-1  , (26),  O,  O\n",
    "\n",
    "[6] RAG  \n",
    " :  ? .  1   .    .  1 1     .  1 1  \n",
    "\n",
    "--- [  (Context)] ---\n",
    " 1: PART\n",
    "01  \n",
    "001   ?\n",
    ".  1  \n",
    ".   \n",
    ".  1 1    \n",
    " \n",
    ".  1 1  \n",
    "/ : ...\n",
    " 2:   .\n",
    "019       \n",
    "    ?\n",
    ".   .\n",
    ".  .\n",
    ".  .\n",
    ".   .\n",
    "/ :      ...\n",
    " 3:  I   \n",
    ".  . \n",
    ".  . \n",
    "/  :    \n",
    "130        \n",
    "  ?\n",
    ".  \n",
    ".   \n",
    ".   \n",
    ". ...\n",
    " 4: 04.       \n",
    "?\n",
    ".      \n",
    "  .\n",
    ".      \n",
    "  .\n",
    ".      \n",
    "  .\n",
    ".  ...\n",
    " 5: . A : mechanical efficiency,\n",
    "B : specific fuel oil consumption \n",
    ". A : thermal efficiency,\n",
    "B : specific fuel oil consumption \n",
    ". A : mechanical eff...\n",
    " 6:  I   \n",
    ".    .\n",
    ".  .\n",
    ".     . \n",
    ".    .\n",
    "/     .\n",
    "062        \n",
    "...\n",
    " 7:  2  [  I ]\n",
    "01.      \n",
    "?\n",
    ".     \n",
    ".      \n",
    ".     \n",
    " \n",
    ".    \n",
    "02.   ...\n",
    "------------------------------\n",
    "--- [ ] ---\n",
    "## Final Answer Format:\n",
    "**Final Answer :** .  1 1    \n",
    "\n",
    "**:**\n",
    "     . Context \":             \"  . ,  1 1      .\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b88e48",
   "metadata": {},
   "source": [
    "1-28.   +  , (32)  O,  X\n",
    "\n",
    "[6] RAG  \n",
    " :             ? .  .  .  . \n",
    "\n",
    "--- [  (Context)] ---\n",
    " 1: /      \n",
    "  .\n",
    "028       \n",
    "       \n",
    "  ?\n",
    ".  . \n",
    ".  . \n",
    "/ ...\n",
    " 2: .\n",
    "/ :      \n",
    ",      \n",
    "      \n",
    "173      \n",
    "  ?\n",
    "170  (sea margin)   \n",
    "...\n",
    " 3: t\n",
    "TBN   .\n",
    ".      \n",
    " TBNO|     \n",
    "  .\n",
    "25.       \n",
    "?\n",
    ".  \n",
    ".  \n",
    ".   \n",
    "...\n",
    " 4: .   \n",
    ".   \n",
    ".   \n",
    ".   \n",
    "/  \n",
    "1.   \n",
    "2.    \n",
    "3.   \n",
    "4.     \n",
    "058      ...\n",
    " 5: J WTER 01     P^ I II\n",
    ".    .\n",
    ".     .\n",
    ".     .\n",
    "S \n",
    ",            ...\n",
    " 6:   04\n",
    "23.      ?\n",
    ".       \n",
    "      \n",
    "       \n",
    " .\n",
    ".    \n",
    " ...\n",
    " 7:      ,   \n",
    "       \n",
    "  .\n",
    "094      \n",
    " ?\n",
    ".   \n",
    ".   \n",
    ".  \n",
    ".  ...\n",
    "------------------------------\n",
    "--- [ ] ---\n",
    "## Final Answer:\n",
    "**Final Answer:** . \n",
    "**:**                . Context \"\"               . , \"\"         . ,              \"\".\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb17b94",
   "metadata": {},
   "source": [
    "1-100.  , (52)  O,  X\n",
    "\n",
    "[6] RAG  \n",
    " :        ? .        .    .      .     \n",
    "\n",
    "--- [  (Context)] ---\n",
    " 1: .   \n",
    ".   \n",
    ".   \n",
    ".   \n",
    "/  \n",
    "1.   \n",
    "2.    \n",
    "3.   \n",
    "4.     \n",
    "058      ...\n",
    " 2: \n",
    "082     ?\n",
    ".   .  \n",
    ".   .  \n",
    "/       \n",
    "      .\n",
    "083  (Oiliness)   ?\n",
    ". ...\n",
    " 3: .      \n",
    ".\n",
    "08.       \n",
    "       \n",
    " ?\n",
    ".    \n",
    ".      \n",
    ".   ...\n",
    " 4:  I   \n",
    ".  . \n",
    ".  . \n",
    "/     .\n",
    "181       \n",
    "  .      \n",
    "?\n",
    ".    \n",
    ". ...\n",
    " 5:      \n",
    " .\n",
    ".   H2SO4   \n",
    "     \n",
    "      \n",
    ".\n",
    "23   ?\n",
    ".   .  \n",
    ". ...\n",
    " 6:  I   \n",
    "034       \n",
    "     ?\n",
    ".   \n",
    ".   \n",
    ".    \n",
    ".   \n",
    "/    ...\n",
    " 7: CHAPTER 01.  |.arE 1.  I\n",
    ".  \n",
    ".     \n",
    ".  \n",
    ".   \n",
    ". \n",
    "0  \n",
    "1)  \n",
    "(1)  \n",
    "   ...\n",
    "------------------------------\n",
    "--- [ ] ---\n",
    "## Final Answer Format:\n",
    "**Final Answer :** .     \n",
    "\n",
    "**:**     .\n",
    ".       :       ,        .\n",
    ".   :    ,        .\n",
    ".     :        ,        .\n",
    ".     :        ,        .\n",
    "\n",
    "        .       ,     .\n",
    "\n",
    "---\n",
    "\n",
    "**Final Answer :** .     \n",
    "\n",
    "**:**         ,  ,    .       ,     .          .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe2149f",
   "metadata": {},
   "source": [
    "2-252.  , (25)  O,  x\n",
    "\n",
    "[6] RAG  \n",
    " :   , ,      ? .   .   .   .  \n",
    "\n",
    "--- [  (Context)] ---\n",
    " 1: II   \n",
    "252    , ,   \n",
    "   ?\n",
    ".   .   \n",
    ".  .  \n",
    "/  :    ,  \n",
    "    ...\n",
    " 2: 2)  : U          \n",
    "        .\n",
    "(   \n",
    "3)  \n",
    "       ...\n",
    " 3:  n   \n",
    "178        \n",
    "?\n",
    ".  . \n",
    ".  . \n",
    "/  :    ,  \n",
    "     .  \n",
    "     ...\n",
    " 4:      \n",
    "110  Rack Pinion     \n",
    "     ,  \n",
    "     ?\n",
    "7}.  gauge\n",
    ". Dial gauge\n",
    "'. Vernier Cal...\n",
    " 5:   03\n",
    "18. (Megger)  ?\n",
    ".  \n",
    ".     \n",
    ". Fuse    \n",
    ".  \n",
    "19.   () 19[mm] \n",
    "20 () 1   \n",
    "[m...\n",
    " 6: 1\n",
    "}. fuel injection valves\n",
    "/       \n",
    "  .\n",
    "287  Nearly all fires can be easily \n",
    "controlled by one man with a portable ( \n",
    ").\n",
    "...\n",
    " 7: .   . \n",
    "/       \n",
    " .\n",
    "021        \n",
    "     \n",
    "   ?\n",
    ".  \n",
    ".  \n",
    "....\n",
    "------------------------------\n",
    "--- [ ] ---\n",
    "## Final Answer Format:\n",
    "**Final Answer :** . \n",
    "\n",
    "**:**\n",
    "   , ,        . Context  ,  , ,      .      ,       ,  U                  .   , ,      .\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea108a",
   "metadata": {},
   "source": [
    "2-120.   . (24),  O,  O\n",
    "\n",
    "[6] RAG  \n",
    " : 1 0   1 0        ? . 1 . 12 . 24 . 48\n",
    "\n",
    "--- [  (Context)] ---\n",
    " 1: .    \n",
    ".   \n",
    ".    \n",
    "/      \n",
    "  ,   \n",
    "  .\n",
    "120  1  o]  1  c] \n",
    " ...\n",
    " 2:   04 \n",
    " Q,kcal]     \n",
    " ?\n",
    ". QJ ( Q, - Q0\n",
    ". QJ ( 0. - Q2)\n",
    ". QJ ( Q, + QJ\n",
    ". QJ ( Q.+ QJ\n",
    "17. 5[PS]       [kcal]\n",
    "...\n",
    " 3:   07\n",
    ".   \n",
    "06      \n",
    "      \n",
    "   ?\n",
    ".     . \n",
    ".     . \n",
    ". ...\n",
    " 4: !]   \n",
    ".    ,  \n",
    "  .\n",
    ".    .\n",
    ".     .\n",
    "/      \n",
    "     .\n",
    "/ ...\n",
    " 5: 190       \n",
    " ?\n",
    ".  . \n",
    ".  . \n",
    "/  :       \n",
    "    \n",
    "191     6kgfl \n",
    "  4[...\n",
    " 6: code.\n",
    ". electricity . engine\n",
    ". weight . velocity\n",
    "22a In accordance with the MARPOL \n",
    "Convention as amended, ( ) is defined \n",
    "as the process whereby...\n",
    " 7:   09 \n",
    " ?\n",
    ".    .\n",
    ".    .\n",
    ".    . \n",
    ".    .\n",
    "16. C]  1kg] 40[]  10[kg] \n",
    "  ...\n",
    "------------------------------\n",
    "--- [ ] ---\n",
    "## Final Answer:\n",
    "**Final Answer:** . 24\n",
    "**:**  0  1 24  0       1  3,320 [kcal/h] . , 1 24  0  1 0   .\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da534c",
   "metadata": {},
   "source": [
    "2-201.   . (34),  .  O,  O\n",
    "\n",
    "[6] RAG  \n",
    " : 90[]  3        ? . 90[] . 15[] . 30[] . 60[]\n",
    "\n",
    "--- [  (Context)] ---\n",
    " 1:   08\n",
    ". 1. 0. 0, o . o, 1, o, o 19     \n",
    ". 0, 0, 1, 0 . 0, 0, 0, 1\n",
    "16    rl  \n",
    "     M?\n",
    "  R\n",
    ">. ~...\n",
    " 2: 200       ?\n",
    ".   .\n",
    ".    .\n",
    ">.   .\n",
    ".  .\n",
    "/       \n",
    "    .\n",
    "20...\n",
    " 3:     .  \n",
    "       \n",
    "       \n",
    " ,      \n",
    "       \n",
    "  .\n",
    "0...\n",
    " 4:   10\n",
    "0  R4   [kQ]?\n",
    ". 4[kQ] . 6[kQ]\n",
    ". 8[kQ] . 10[kQ]\n",
    ". 6.2[kW] . 8.8[kW]\n",
    ". 12.2[kW] . 16.2[kW]\n",
    "07     \n",
    "?\n",
    "...\n",
    " 5:  \n",
    " \n",
    ".       \n",
    ".       \n",
    ".      \n",
    "23.       ?\n",
    ". Euler . Froude\n",
    ". Weber...\n",
    " 6:  ? ,    3 kgfl   \n",
    "     .\n",
    ". 3 . 6\n",
    "E 9 . 27\n",
    "/  0.2  800 x 0.2 / 30 = 5.48 \n",
    "  6.\n",
    "045  427[PS] ...\n",
    " 7:  9  [  m ]\n",
    "01.    (Wheatstone \n",
    "bridge)   Rx ? (, R, \n",
    "=1, R2=2, R3=3  \n",
    " G    .) \n",
    ". 2 . 4\n",
    ". 5(...\n",
    "------------------------------\n",
    "--- [ ] ---\n",
    "## Final Answer:\n",
    "**Final Answer :** . 30[]\n",
    "\n",
    "**:**\n",
    " 90[]  3          .      ,     .  3         . 3   ,    90[] / 3 = 30[] .  3         30[].\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df595cc1",
   "metadata": {},
   "source": [
    "3-74.   . (24),  O, \n",
    "\n",
    "[6] RAG  \n",
    " :      ? .   (Seebeck effect) .   .   (Hall effect) .   (Doppler effect)\n",
    "\n",
    "--- [  (Context)] ---\n",
    " 1:  .\n",
    "073      ?\n",
    ".      . \n",
    ".      . \n",
    ".       . \n",
    ".     .\n",
    "/   ...\n",
    " 2:  .\n",
    "102   3[w],  \n",
    " 5VA]   ?\n",
    ". 0.5 . 0.6 ?. 0.7 . 0.8\n",
    "/  =  / \n",
    "103      ?\n",
    ".    ...\n",
    " 3: .  .  \n",
    ".   . \n",
    "/   :    \n",
    " \n",
    "066       ?\n",
    ".  KSeebeck effect) . \n",
    ".   .\n",
    "....\n",
    " 4:     ?\n",
    ".   .  \n",
    ".   .  \n",
    "/      \n",
    "      \n",
    "  .\n",
    "198     ...\n",
    " 5:      , \n",
    "     \n",
    "  \n",
    "142     ?\n",
    ".    .\n",
    ".  .\n",
    ".   .\n",
    ".   \n",
    "/...\n",
    " 6: 02.      \n",
    "     \n",
    " ?\n",
    ".   .   \n",
    ".   .  \n",
    "03.1    ()  \n",
    "     ...\n",
    " 7: \n",
    "\n",
    ".  . \n",
    ".  . \n",
    "17     \n",
    "       \n",
    "      \n",
    " ?\n",
    ".  .  .  . \n",
    "18 ...\n",
    "------------------------------\n",
    "--- [ ] ---\n",
    "## Final Answer Format:\n",
    "**Final Answer :** .  \n",
    "\n",
    "**:**\n",
    "       . Context     \"  :               ,          ,       \"  .      .\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef20c2",
   "metadata": {},
   "source": [
    "4-226.  +  . (37),  O,  X\n",
    "\n",
    "[6] RAG  \n",
    " :         ? .    .   10   22.5         .       (tank)   .   (tank air vent)     \n",
    "\n",
    "--- [  (Context)] ---\n",
    " 1:       ? \n",
    ".   \n",
    ".   10   \n",
    " 22.5    \n",
    "    \n",
    ".       \n",
    " (tank)  ...\n",
    " 2:    \n",
    "       \n",
    "   .\n",
    "223       \n",
    "      ?\n",
    ".      \n",
    "  \n",
    ". ...\n",
    " 3: 217        \n",
    "?\n",
    ".   15[ppm]   \n",
    "  \n",
    ".  25   \n",
    "      \n",
    " \n",
    ".       ...\n",
    " 4: s\n",
    ".        \n",
    "  .\n",
    "/         \n",
    "   .\n",
    "162        \n",
    "     \n",
    " ?\n",
    "....\n",
    " 5: .       \n",
    "      \n",
    "1.       \n",
    ".      \n",
    "    \n",
    "/     25 \n",
    "...\n",
    " 6:  47  472    \n",
    "     .\n",
    "1.        \n",
    "    \n",
    "\n",
    "2.       \n",
    " ...\n",
    " 7:  .\n",
    ".    \n",
    " .\n",
    ".      \n",
    " .\n",
    "04.       \n",
    "  ?\n",
    ".      \n",
    ".\n",
    ". ...\n",
    "------------------------------\n",
    "--- [ ] ---\n",
    "## Final Answer:\n",
    "**Final Answer:** .       (tank)  \n",
    "**:**      .\n",
    "1)  :  \n",
    "2)  :   10   22.5        \n",
    "3)  : ,,,,,,, , ,                \n",
    ",       (tank)       .\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3544543",
   "metadata": {},
   "source": [
    "*  \n",
    "5/8 = 0.625\n",
    "\n",
    "*bge-m3 \n",
    " O\n",
    "\n",
    "*Gemma-3-n\n",
    "    X,   O->   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c060b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f668c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929f20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187769db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f49024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763e838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ab3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_p_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
